---
title: "Berlin Airbnb Rental Demand Prediction - Model Development"
author: "Data Science Team"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    theme: cosmo
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                     warning = FALSE, 
                     message = FALSE,
                     fig.width = 10, 
                     fig.height = 6)

# Load necessary libraries
library(tidyverse)      # For data manipulation and visualization
library(randomForest)   # For Random Forest modeling
library(xgboost)        # For XGBoost modeling (if needed)
library(caret)          # For model evaluation and cross-validation
library(gridExtra)      # For arranging multiple plots
library(viridis)        # For better color palettes
library(doParallel)     # For parallel processing
```

# Introduction

This document outlines the development of a predictive model for Airbnb rental demand in Berlin. We'll use the processed data to train a Random Forest model to predict our demand proxy.

## Loading Processed Data

First, let's load the processed data:

```{r load_data}
# Set file paths
processed_data_path <- "../data/processed/"
models_path <- "../models/"
results_path <- "../results/"

# Create directories if they don't exist
if (!dir.exists(models_path)) {
  dir.create(models_path, recursive = TRUE)
}

if (!dir.exists(results_path)) {
  dir.create(results_path, recursive = TRUE)
}

# Load the processed data
message("Loading processed data...")
train_data <- read.csv(paste0(processed_data_path, "train_berlin_clean.csv"))
test_data <- read.csv(paste0(processed_data_path, "test_berlin_clean.csv"))

# Print summary info
message("Train dataset dimensions: ", nrow(train_data), " rows, ", ncol(train_data), " columns")
message("Test dataset dimensions: ", nrow(test_data), " rows, ", ncol(test_data), " columns")
```

## Data Preparation for Modeling

Let's prepare our data for modeling by handling missing values and converting categorical variables to factors:

```{r data_prep}
# Handle missing values
# Simple imputation for numeric columns
numeric_cols <- sapply(train_data, is.numeric)
for (col in names(train_data)[numeric_cols]) {
  if (any(is.na(train_data[[col]]))) {
    median_val <- median(train_data[[col]], na.rm = TRUE)
    train_data[[col]][is.na(train_data[[col]])] <- median_val
  }
}

# Simple imputation for categorical columns
categorical_cols <- c("property_type", "room_type", "host_response_time", 
                     "host_response_rate", "host_is_superhost", "neighborhood_group",
                     "price_tier", "review_scores_rating")

for (col in categorical_cols) {
  if (col %in% names(train_data) && any(is.na(train_data[[col]]))) {
    mode_val <- names(sort(table(train_data[[col]]), decreasing = TRUE))[1]
    train_data[[col]][is.na(train_data[[col]])] <- mode_val
  }
}

# Convert categorical columns to factors with limited cardinality
for (col in categorical_cols) {
  if (col %in% names(train_data)) {
    # Check number of unique values first
    n_unique <- length(unique(train_data[[col]]))
    if (n_unique < 50) {  # Avoid high cardinality factors
      train_data[[col]] <- as.factor(train_data[[col]])
    }
  }
}

# Print info about categorical variables
cat("Categorical variables converted to factors:\n")
for (col in names(train_data)) {
  if (is.factor(train_data[[col]])) {
    cat(sprintf("%s: %d levels\n", col, length(levels(train_data[[col]]))))
  }
}
```

## Feature Selection

Let's select the features we'll use for our model:

```{r feature_selection}
# Set target variable
target_var <- "demand_proxy"

# Select features for modeling (exclude identifiers and high-cardinality variables)
exclude_vars <- c("id", "listing_url", "scrape_id", "last_scraped", "name", 
                 "description", "neighborhood_overview", "host_id", "host_url", 
                 "host_name", "host_location", "host_about", "listing_name",
                 "neighbourhood", "latitude", "longitude")

# Select columns that exist in our dataset
exclude_vars <- exclude_vars[exclude_vars %in% names(train_data)]

# Get feature columns for modeling
feature_cols <- setdiff(names(train_data), c(exclude_vars, target_var))

# Print selected features
cat("Selected", length(feature_cols), "features for modeling\n")
```

## Train-Validation Split

Let's split our training data into a training and validation set:

```{r train_val_split}
# Set seed for reproducibility
set.seed(123)

# Create an 80-20 train-validation split
train_indices <- sample(1:nrow(train_data), size = 0.8 * nrow(train_data))
train_set <- train_data[train_indices, ]
val_set <- train_data[-train_indices, ]

# Print dimensions
cat("Training set:", nrow(train_set), "rows\n")
cat("Validation set:", nrow(val_set), "rows\n")
```

## Random Forest Model Training

Now, let's train a Random Forest model:

```{r rf_model}
# Set up parallel processing
n_cores <- max(1, parallel::detectCores() - 1)  # Leave one core free
cl <- makeCluster(n_cores)
registerDoParallel(cl)

# Start timing
start_time <- Sys.time()

message("Training Random Forest model...")
# Create model formula
features_formula <- as.formula(paste(target_var, "~", paste(feature_cols, collapse = "+")))

# Train model
rf_model <- randomForest(
  formula = features_formula,
  data = train_set,
  ntree = 500,
  mtry = floor(sqrt(length(feature_cols))),
  importance = TRUE
)

# End timing
end_time <- Sys.time()
train_time <- difftime(end_time, start_time, units = "mins")
message("Model training completed in ", round(train_time, 2), " minutes")

# Stop parallel processing
stopCluster(cl)
```

## Model Evaluation

Let's evaluate our model on the validation set:

```{r model_evaluation}
# Make predictions on validation set
val_predictions <- predict(rf_model, val_set)

# Calculate evaluation metrics
rmse <- sqrt(mean((val_set[[target_var]] - val_predictions)^2))
mae <- mean(abs(val_set[[target_var]] - val_predictions))
r_squared <- 1 - sum((val_set[[target_var]] - val_predictions)^2) / 
  sum((val_set[[target_var]] - mean(val_set[[target_var]]))^2)

# Print metrics
cat("Model Performance Metrics:\n")
cat("RMSE:", round(rmse, 4), "\n")
cat("MAE:", round(mae, 4), "\n")
cat("R-squared:", round(r_squared, 4), "\n")

# Create evaluation metrics dataframe
metrics_df <- data.frame(
  metric = c("RMSE", "MAE", "R_squared"),
  value = c(rmse, mae, r_squared)
)

# Save metrics
write.csv(metrics_df, paste0(results_path, "model_performance_metrics.csv"), row.names = FALSE)
```

## Visualizing Actual vs. Predicted Values

Let's visualize the relationship between actual and predicted values:

```{r actual_vs_predicted}
# Create a data frame with actual and predicted values
pred_df <- data.frame(
  actual = val_set[[target_var]],
  predicted = val_predictions
)

# Create the scatter plot
actual_vs_pred_plot <- ggplot(pred_df, aes(x = actual, y = predicted)) +
  geom_point(alpha = 0.5, color = viridis(1, alpha = 0.7)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Actual vs. Predicted Demand",
       x = "Actual Demand",
       y = "Predicted Demand") +
  theme_minimal()

# Display plot
print(actual_vs_pred_plot)

# Save plot
ggsave(paste0(results_path, "rf_actual_vs_predicted.png"), actual_vs_pred_plot, 
      width = 10, height = 8)
```

## Feature Importance

Let's examine which features are most important for our model:

```{r feature_importance}
# Extract feature importance
importance_df <- as.data.frame(importance(rf_model))
importance_df$Feature <- rownames(importance_df)
rownames(importance_df) <- NULL

# Sort by importance
importance_df <- importance_df[order(importance_df$`%IncMSE`, decreasing = TRUE), ]

# Create importance plot
importance_plot <- ggplot(head(importance_df, 20), 
                        aes(x = reorder(Feature, `%IncMSE`), y = `%IncMSE`)) +
  geom_bar(stat = "identity", fill = viridis(1)) +
  coord_flip() +
  labs(title = "Top 20 Features by Importance",
       x = "Feature",
       y = "Importance (%IncMSE)") +
  theme_minimal()

# Display plot
print(importance_plot)

# Save plot and data
ggsave(paste0(results_path, "rf_feature_importance.png"), importance_plot, 
      width = 12, height = 8)
write.csv(importance_df, paste0(results_path, "feature_importance.csv"), row.names = FALSE)

# Print top 10 most important features
cat("Top 10 Most Important Features:\n")
print(head(importance_df[, c("Feature", "%IncMSE")], 10))
```

## Saving the Model

Finally, let's save our trained model for future use:

```{r save_model}
# Save model
saveRDS(rf_model, paste0(models_path, "random_forest_model.rds"))
message("Model saved to ", paste0(models_path, "random_forest_model.rds"))
```

# Conclusion

We have successfully trained a Random Forest model to predict Airbnb rental demand in Berlin. The model shows strong performance with an RÂ² of `r round(r_squared, 3)`, indicating it captures most of the variance in our demand proxy.

The most important features for predicting demand include:

1. `r importance_df$Feature[1]`
2. `r importance_df$Feature[2]`
3. `r importance_df$Feature[3]`
4. `r importance_df$Feature[4]`
5. `r importance_df$Feature[5]`

These insights can help hosts understand what factors most strongly influence demand for their properties.

```{r session_info, echo=FALSE}
# Session information
sessionInfo()
``` 